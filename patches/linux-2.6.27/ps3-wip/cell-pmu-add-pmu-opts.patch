Subject: Cell: Add platform abstraction to pmu routines

Add a platform abstraction layer for access to the Cell processor's
performance monitor features and hookup the routines that do MMIO
access.

This abstraction simplifies the code needed to support all the
cell platforms by allowing a generic set of routines to handle
the bulk of the performance monitor support.  Those generic
routines then use a small set of platform specific routines
that are called indirectly through pointers initialized at
runtime.

Signed-off-by: Geoff Levand <geoffrey.levand@am.sony.com>
---
 arch/powerpc/include/asm/cell-pmu.h    |  151 +++++++++++++++++++++++++++------
 arch/powerpc/platforms/cell/Makefile   |    1 
 arch/powerpc/platforms/cell/pmu-core.c |   31 ++++++
 arch/powerpc/platforms/cell/pmu.c      |  127 +++++++++++++++------------
 4 files changed, 230 insertions(+), 80 deletions(-)

--- a/arch/powerpc/include/asm/cell-pmu.h
+++ b/arch/powerpc/include/asm/cell-pmu.h
@@ -73,33 +73,136 @@ enum pm_reg_name {
 	pm_start_stop,
 };
 
-/* Routines for reading/writing the PMU registers. */
-extern u32  cbe_read_phys_ctr(u32 cpu, u32 phys_ctr);
-extern void cbe_write_phys_ctr(u32 cpu, u32 phys_ctr, u32 val);
-extern u32  cbe_read_ctr(u32 cpu, u32 ctr);
-extern void cbe_write_ctr(u32 cpu, u32 ctr, u32 val);
-
-extern u32  cbe_read_pm07_control(u32 cpu, u32 ctr);
-extern void cbe_write_pm07_control(u32 cpu, u32 ctr, u32 val);
-extern u32  cbe_read_pm(u32 cpu, enum pm_reg_name reg);
-extern void cbe_write_pm(u32 cpu, enum pm_reg_name reg, u32 val);
-
-extern u32  cbe_get_ctr_size(u32 cpu, u32 phys_ctr);
-extern void cbe_set_ctr_size(u32 cpu, u32 phys_ctr, u32 ctr_size);
-
-extern void cbe_enable_pm(u32 cpu);
-extern void cbe_disable_pm(u32 cpu);
-
-extern void cbe_read_trace_buffer(u32 cpu, u64 *buf);
-
-extern void cbe_enable_pm_interrupts(u32 cpu, u32 thread, u32 mask);
-extern void cbe_disable_pm_interrupts(u32 cpu);
-extern u32  cbe_get_and_clear_pm_interrupts(u32 cpu);
-extern void cbe_sync_irq(int node);
-
 #define CBE_COUNT_SUPERVISOR_MODE       0
 #define CBE_COUNT_HYPERVISOR_MODE       1
 #define CBE_COUNT_PROBLEM_MODE          2
 #define CBE_COUNT_ALL_MODES             3
 
+/**
+ * struct cell_pmu_ops - Provides a platfrom independent PMU abstraction.
+ * @priv: Void pointer variable for platform driver use.
+ */
+
+struct cell_pmu_ops {
+	void* priv;
+	u32 (*read_phys_ctr)(void* p, u32 cpu, u32 phys_ctr);
+	void (*write_phys_ctr)(void* p, u32 cpu, u32 phys_ctr, u32 val);
+	u32 (*read_ctr)(void* p, u32 cpu, u32 ctr);
+	void (*write_ctr)(void* p, u32 cpu, u32 ctr, u32 val);
+	u32 (*read_pm07_control)(void* p, u32 cpu, u32 ctr);
+	void (*write_pm07_control)(void* p, u32 cpu, u32 ctr, u32 val);
+	u32 (*read_pm)(void* p, u32 cpu, enum pm_reg_name reg);
+	void (*write_pm)(void* p, u32 cpu, enum pm_reg_name reg, u32 val);
+	u32  (*get_ctr_size)(void* p, u32 cpu, u32 phys_ctr);
+	void (*set_ctr_size)(void* p, u32 cpu, u32 phys_ctr, u32 ctr_size);
+	void (*enable_pm)(void* p, u32 cpu);
+	void (*disable_pm)(void* p, u32 cpu);
+	void (*read_trace_buffer)(void* p, u32 cpu, u64 *buf);
+	u32  (*get_and_clear_pm_interrupts)(void* p, u32 cpu);
+	void (*enable_pm_interrupts)(void* p, u32 cpu, u32 thread, u32 mask);
+	void (*disable_pm_interrupts)(void* p, u32 cpu);
+	void (*sync_irq)(void* p, int node);
+};
+
+extern const struct cell_pmu_ops *cell_pmu_ops;
+
+/**
+ * cell_pmu_ops_init - Initialize the cell_pmu_ops pointer.
+ * @ops: A platfrom specific instance of struct cell_pmu_ops.
+ */
+
+static inline void cell_pmu_ops_init(const struct cell_pmu_ops *ops)
+{
+	cell_pmu_ops = ops;
+}
+
+/* Routines for reading/writing the PMU registers. */
+
+static inline u32 cbe_read_phys_ctr(u32 cpu, u32 phys_ctr)
+{
+	return cell_pmu_ops->read_phys_ctr(cell_pmu_ops->priv, cpu, phys_ctr);
+}
+
+static inline void cbe_write_phys_ctr(u32 cpu, u32 phys_ctr, u32 val)
+{
+	cell_pmu_ops->write_phys_ctr(cell_pmu_ops->priv, cpu, phys_ctr, val);
+}
+
+static inline u32 cbe_read_ctr(u32 cpu, u32 ctr)
+{
+	return cell_pmu_ops->read_ctr(cell_pmu_ops->priv, cpu, ctr);
+}
+
+static inline void cbe_write_ctr(u32 cpu, u32 ctr, u32 val)
+{
+	cell_pmu_ops->write_ctr(cell_pmu_ops->priv, cpu, ctr, val);
+}
+
+static inline u32  cbe_read_pm07_control(u32 cpu, u32 ctr)
+{
+	return cell_pmu_ops->read_pm07_control(cell_pmu_ops->priv, cpu, ctr);
+}
+
+static inline void cbe_write_pm07_control(u32 cpu, u32 ctr, u32 val)
+{
+	cell_pmu_ops->write_pm07_control(cell_pmu_ops->priv, cpu, ctr, val);
+}
+
+static inline u32  cbe_read_pm(u32 cpu, enum pm_reg_name reg)
+{
+	return cell_pmu_ops->read_pm(cell_pmu_ops->priv, cpu, reg);
+}
+
+static inline void cbe_write_pm(u32 cpu, enum pm_reg_name reg, u32 val)
+{
+	cell_pmu_ops->write_pm(cell_pmu_ops->priv, cpu, reg, val);
+}
+
+static inline u32 cbe_get_ctr_size(u32 cpu, u32 phys_ctr)
+{
+	return cell_pmu_ops->get_ctr_size(cell_pmu_ops->priv, cpu, phys_ctr);
+}
+
+static inline void cbe_set_ctr_size(u32 cpu, u32 phys_ctr, u32 ctr_size)
+{
+	cell_pmu_ops->set_ctr_size(cell_pmu_ops->priv, cpu, phys_ctr, ctr_size);
+}
+
+static inline void cbe_enable_pm(u32 cpu)
+{
+	cell_pmu_ops->enable_pm(cell_pmu_ops->priv, cpu);
+}
+
+static inline void cbe_disable_pm(u32 cpu)
+{
+	return cell_pmu_ops->disable_pm(cell_pmu_ops->priv, cpu);
+}
+
+static inline void cbe_read_trace_buffer(u32 cpu, u64 *buf)
+{
+	cell_pmu_ops->read_trace_buffer(cell_pmu_ops->priv, cpu, buf);
+}
+
+static inline void cbe_enable_pm_interrupts(u32 cpu, u32 thread, u32 mask)
+{
+	cell_pmu_ops->enable_pm_interrupts(cell_pmu_ops->priv, cpu, thread,
+		mask);
+}
+
+static inline void cbe_disable_pm_interrupts(u32 cpu)
+{
+	cell_pmu_ops->disable_pm_interrupts(cell_pmu_ops->priv, cpu);
+}
+
+static inline u32  cbe_get_and_clear_pm_interrupts(u32 cpu)
+{
+	return cell_pmu_ops->get_and_clear_pm_interrupts(cell_pmu_ops->priv,
+		cpu);
+}
+
+static inline void cbe_sync_irq(int node)
+{
+	cell_pmu_ops->sync_irq(cell_pmu_ops->priv, node);
+}
+
 #endif /* __ASM_CELL_PMU_H__ */
--- a/arch/powerpc/platforms/cell/Makefile
+++ b/arch/powerpc/platforms/cell/Makefile
@@ -1,3 +1,4 @@
+obj-$(CONFIG_PPC_CELL)			+= pmu-core.o
 obj-$(CONFIG_PPC_CELL_NATIVE)		+= interrupt.o iommu.o setup.o \
 					   cbe_regs.o spider-pic.o \
 					   pervasive.o pmu.o io-workarounds.o \
--- /dev/null
+++ b/arch/powerpc/platforms/cell/pmu-core.c
@@ -0,0 +1,31 @@
+/*
+ * Core support for Cell Performance Monitor Unit.
+ *
+ *  Copyright (C) 2008 Sony Computer Entertainment Inc.
+ *  Copyright 2008 Sony Corp.
+ *
+ *  This program is free software; you can redistribute it and/or modify
+ *  it under the terms of the GNU General Public License as published by
+ *  the Free Software Foundation; version 2 of the License.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <asm/cell-pmu.h>
+
+
+/**
+ * cell_pmu_ops - Global pointer to the platform specific cell_pmu_ops instance.
+ */
+
+const struct cell_pmu_ops *cell_pmu_ops;
+EXPORT_SYMBOL_GPL(cell_pmu_ops);
--- a/arch/powerpc/platforms/cell/pmu.c
+++ b/arch/powerpc/platforms/cell/pmu.c
@@ -69,7 +69,7 @@
  * Other PMU control registers. Most of these are write-only.
  */
 
-u32 cbe_read_pm(u32 cpu, enum pm_reg_name reg)
+static u32 mmio_read_pm(__maybe_unused void* p, u32 cpu, enum pm_reg_name reg)
 {
 	u32 val = 0;
 
@@ -109,9 +109,9 @@ u32 cbe_read_pm(u32 cpu, enum pm_reg_nam
 
 	return val;
 }
-EXPORT_SYMBOL_GPL(cbe_read_pm);
 
-void cbe_write_pm(u32 cpu, enum pm_reg_name reg, u32 val)
+static void mmio_write_pm(__maybe_unused void* p, u32 cpu, enum pm_reg_name reg,
+	u32 val)
 {
 	switch (reg) {
 	case group_control:
@@ -147,31 +147,30 @@ void cbe_write_pm(u32 cpu, enum pm_reg_n
 		break;
 	}
 }
-EXPORT_SYMBOL_GPL(cbe_write_pm);
 
 /*
  * Get/set the size of a physical counter to either 16 or 32 bits.
  */
 
-u32 cbe_get_ctr_size(u32 cpu, u32 phys_ctr)
+static u32 mmio_get_ctr_size(__maybe_unused void* p, u32 cpu, u32 phys_ctr)
 {
 	u32 pm_ctrl, size = 0;
 
 	if (phys_ctr < NR_PHYS_CTRS) {
-		pm_ctrl = cbe_read_pm(cpu, pm_control);
+		pm_ctrl = mmio_read_pm(p, cpu, pm_control);
 		size = (pm_ctrl & CBE_PM_16BIT_CTR(phys_ctr)) ? 16 : 32;
 	}
 
 	return size;
 }
-EXPORT_SYMBOL_GPL(cbe_get_ctr_size);
 
-void cbe_set_ctr_size(u32 cpu, u32 phys_ctr, u32 ctr_size)
+static void mmio_set_ctr_size(__maybe_unused void* p, u32 cpu, u32 phys_ctr,
+	u32 ctr_size)
 {
 	u32 pm_ctrl;
 
 	if (phys_ctr < NR_PHYS_CTRS) {
-		pm_ctrl = cbe_read_pm(cpu, pm_control);
+		pm_ctrl = mmio_read_pm(p, cpu, pm_control);
 		switch (ctr_size) {
 		case 16:
 			pm_ctrl |= CBE_PM_16BIT_CTR(phys_ctr);
@@ -181,17 +180,16 @@ void cbe_set_ctr_size(u32 cpu, u32 phys_
 			pm_ctrl &= ~CBE_PM_16BIT_CTR(phys_ctr);
 			break;
 		}
-		cbe_write_pm(cpu, pm_control, pm_ctrl);
+		mmio_write_pm(p, cpu, pm_control, pm_ctrl);
 	}
 }
-EXPORT_SYMBOL_GPL(cbe_set_ctr_size);
 
 /*
  * Physical counter registers.
  * Each physical counter can act as one 32-bit counter or two 16-bit counters.
  */
 
-u32 cbe_read_phys_ctr(u32 cpu, u32 phys_ctr)
+static u32 mmio_read_phys_ctr(__maybe_unused void* p, u32 cpu, u32 phys_ctr)
 {
 	u32 val_in_latch, val = 0;
 
@@ -208,9 +206,9 @@ u32 cbe_read_phys_ctr(u32 cpu, u32 phys_
 
 	return val;
 }
-EXPORT_SYMBOL_GPL(cbe_read_phys_ctr);
 
-void cbe_write_phys_ctr(u32 cpu, u32 phys_ctr, u32 val)
+static void mmio_write_phys_ctr(__maybe_unused void* p, u32 cpu, u32 phys_ctr,
+	u32 val)
 {
 	struct cbe_pmd_shadow_regs *shadow_regs;
 	u32 pm_ctrl;
@@ -222,20 +220,19 @@ void cbe_write_phys_ctr(u32 cpu, u32 phy
 		 */
 		WRITE_WO_MMIO(pm_ctr[phys_ctr], val);
 
-		pm_ctrl = cbe_read_pm(cpu, pm_control);
+		pm_ctrl = mmio_read_pm(p, cpu, pm_control);
 		if (pm_ctrl & CBE_PM_ENABLE_PERF_MON) {
 			/* The counters are already active, so we need to
 			 * rewrite the pm_control register to "re-enable"
 			 * the PMU.
 			 */
-			cbe_write_pm(cpu, pm_control, pm_ctrl);
+			mmio_write_pm(p, cpu, pm_control, pm_ctrl);
 		} else {
 			shadow_regs = cbe_get_cpu_pmd_shadow_regs(cpu);
 			shadow_regs->counter_value_in_latch |= (1 << phys_ctr);
 		}
 	}
 }
-EXPORT_SYMBOL_GPL(cbe_write_phys_ctr);
 
 /*
  * "Logical" counter registers.
@@ -243,29 +240,28 @@ EXPORT_SYMBOL_GPL(cbe_write_phys_ctr);
  * current size of the counter. Counters 4 - 7 are always 16-bit.
  */
 
-u32 cbe_read_ctr(u32 cpu, u32 ctr)
+static u32 mmio_read_ctr(__maybe_unused void* p, u32 cpu, u32 ctr)
 {
 	u32 val;
 	u32 phys_ctr = ctr & (NR_PHYS_CTRS - 1);
 
-	val = cbe_read_phys_ctr(cpu, phys_ctr);
+	val = mmio_read_phys_ctr(p, cpu, phys_ctr);
 
-	if (cbe_get_ctr_size(cpu, phys_ctr) == 16)
+	if (mmio_get_ctr_size(p, cpu, phys_ctr) == 16)
 		val = (ctr < NR_PHYS_CTRS) ? (val >> 16) : (val & 0xffff);
 
 	return val;
 }
-EXPORT_SYMBOL_GPL(cbe_read_ctr);
 
-void cbe_write_ctr(u32 cpu, u32 ctr, u32 val)
+static void mmio_write_ctr(__maybe_unused void* p, u32 cpu, u32 ctr, u32 val)
 {
 	u32 phys_ctr;
 	u32 phys_val;
 
 	phys_ctr = ctr & (NR_PHYS_CTRS - 1);
 
-	if (cbe_get_ctr_size(cpu, phys_ctr) == 16) {
-		phys_val = cbe_read_phys_ctr(cpu, phys_ctr);
+	if (mmio_get_ctr_size(p, cpu, phys_ctr) == 16) {
+		phys_val = mmio_read_phys_ctr(p, cpu, phys_ctr);
 
 		if (ctr < NR_PHYS_CTRS)
 			val = (val << 16) | (phys_val & 0xffff);
@@ -273,16 +269,15 @@ void cbe_write_ctr(u32 cpu, u32 ctr, u32
 			val = (val & 0xffff) | (phys_val & 0xffff0000);
 	}
 
-	cbe_write_phys_ctr(cpu, phys_ctr, val);
+	mmio_write_phys_ctr(p, cpu, phys_ctr, val);
 }
-EXPORT_SYMBOL_GPL(cbe_write_ctr);
 
 /*
  * Counter-control registers.
  * Each "logical" counter has a corresponding control register.
  */
 
-u32 cbe_read_pm07_control(u32 cpu, u32 ctr)
+static u32 mmio_read_pm07_control(__maybe_unused void* p, u32 cpu, u32 ctr)
 {
 	u32 pm07_control = 0;
 
@@ -291,21 +286,20 @@ u32 cbe_read_pm07_control(u32 cpu, u32 c
 
 	return pm07_control;
 }
-EXPORT_SYMBOL_GPL(cbe_read_pm07_control);
 
-void cbe_write_pm07_control(u32 cpu, u32 ctr, u32 val)
+static void mmio_write_pm07_control(__maybe_unused void* p, u32 cpu, u32 ctr,
+	u32 val)
 {
 	if (ctr < NR_CTRS)
 		WRITE_WO_MMIO(pm07_control[ctr], val);
 }
-EXPORT_SYMBOL_GPL(cbe_write_pm07_control);
 
 /*
  * Enable/disable the entire performance monitoring unit.
  * When we enable the PMU, all pending writes to counters get committed.
  */
 
-void cbe_enable_pm(u32 cpu)
+static void mmio_enable_pm(__maybe_unused void* p, u32 cpu)
 {
 	struct cbe_pmd_shadow_regs *shadow_regs;
 	u32 pm_ctrl;
@@ -313,18 +307,16 @@ void cbe_enable_pm(u32 cpu)
 	shadow_regs = cbe_get_cpu_pmd_shadow_regs(cpu);
 	shadow_regs->counter_value_in_latch = 0;
 
-	pm_ctrl = cbe_read_pm(cpu, pm_control) | CBE_PM_ENABLE_PERF_MON;
-	cbe_write_pm(cpu, pm_control, pm_ctrl);
+	pm_ctrl = mmio_read_pm(p, cpu, pm_control) | CBE_PM_ENABLE_PERF_MON;
+	mmio_write_pm(p, cpu, pm_control, pm_ctrl);
 }
-EXPORT_SYMBOL_GPL(cbe_enable_pm);
 
-void cbe_disable_pm(u32 cpu)
+static void mmio_disable_pm(__maybe_unused void* p, u32 cpu)
 {
 	u32 pm_ctrl;
-	pm_ctrl = cbe_read_pm(cpu, pm_control) & ~CBE_PM_ENABLE_PERF_MON;
-	cbe_write_pm(cpu, pm_control, pm_ctrl);
+	pm_ctrl = mmio_read_pm(p, cpu, pm_control) & ~CBE_PM_ENABLE_PERF_MON;
+	mmio_write_pm(p, cpu, pm_control, pm_ctrl);
 }
-EXPORT_SYMBOL_GPL(cbe_disable_pm);
 
 /*
  * Reading from the trace_buffer.
@@ -332,45 +324,42 @@ EXPORT_SYMBOL_GPL(cbe_disable_pm);
  * the second half automatically increments the trace_address.
  */
 
-void cbe_read_trace_buffer(u32 cpu, u64 *buf)
+static void mmio_read_trace_buffer(__maybe_unused void* p, u32 cpu, u64 *buf)
 {
 	struct cbe_pmd_regs __iomem *pmd_regs = cbe_get_cpu_pmd_regs(cpu);
 
 	*buf++ = in_be64(&pmd_regs->trace_buffer_0_63);
 	*buf++ = in_be64(&pmd_regs->trace_buffer_64_127);
 }
-EXPORT_SYMBOL_GPL(cbe_read_trace_buffer);
 
 /*
  * Enabling/disabling interrupts for the entire performance monitoring unit.
  */
 
-u32 cbe_get_and_clear_pm_interrupts(u32 cpu)
+static u32 mmio_get_and_clear_pm_interrupts(__maybe_unused void* p, u32 cpu)
 {
 	/* Reading pm_status clears the interrupt bits. */
-	return cbe_read_pm(cpu, pm_status);
+	return mmio_read_pm(p, cpu, pm_status);
 }
-EXPORT_SYMBOL_GPL(cbe_get_and_clear_pm_interrupts);
 
-void cbe_enable_pm_interrupts(u32 cpu, u32 thread, u32 mask)
+static void mmio_enable_pm_interrupts(__maybe_unused void* p, u32 cpu,
+	u32 thread, u32 mask)
 {
 	/* Set which node and thread will handle the next interrupt. */
 	iic_set_interrupt_routing(cpu, thread, 0);
 
 	/* Enable the interrupt bits in the pm_status register. */
 	if (mask)
-		cbe_write_pm(cpu, pm_status, mask);
+		mmio_write_pm(p, cpu, pm_status, mask);
 }
-EXPORT_SYMBOL_GPL(cbe_enable_pm_interrupts);
 
-void cbe_disable_pm_interrupts(u32 cpu)
+static void mmio_disable_pm_interrupts(__maybe_unused void* p, u32 cpu)
 {
-	cbe_get_and_clear_pm_interrupts(cpu);
-	cbe_write_pm(cpu, pm_status, 0);
+	mmio_get_and_clear_pm_interrupts(p, cpu);
+	mmio_write_pm(p, cpu, pm_status, 0);
 }
-EXPORT_SYMBOL_GPL(cbe_disable_pm_interrupts);
 
-void cbe_sync_irq(int node)
+static void mmio_sync_irq(__maybe_unused void* p, int node)
 {
 	unsigned int irq;
 
@@ -386,15 +375,34 @@ void cbe_sync_irq(int node)
 
 	synchronize_irq(irq);
 }
-EXPORT_SYMBOL_GPL(cbe_sync_irq);
 
-static irqreturn_t cbe_pm_irq(int irq, void *dev_id)
+static const struct cell_pmu_ops cell_pmu_ops_mmio = {
+	.read_phys_ctr               = mmio_read_phys_ctr,
+	.write_phys_ctr              = mmio_write_phys_ctr,
+	.read_ctr                    = mmio_read_ctr,
+	.write_ctr	             = mmio_write_ctr,
+	.read_pm07_control           = mmio_read_pm07_control,
+	.write_pm07_control          = mmio_write_pm07_control,
+	.read_pm                     = mmio_read_pm,
+	.write_pm                    = mmio_write_pm,
+	.get_ctr_size                = mmio_get_ctr_size,
+	.set_ctr_size                = mmio_set_ctr_size,
+	.enable_pm                   = mmio_enable_pm,
+	.disable_pm                  = mmio_disable_pm,
+	.read_trace_buffer           = mmio_read_trace_buffer,
+	.get_and_clear_pm_interrupts = mmio_get_and_clear_pm_interrupts,
+	.enable_pm_interrupts        = mmio_enable_pm_interrupts,
+	.disable_pm_interrupts       = mmio_disable_pm_interrupts,
+	.sync_irq                    = mmio_sync_irq,
+};
+
+static irqreturn_t mmio_pm_irq(int irq, void *dev_id)
 {
 	perf_irq(get_irq_regs());
 	return IRQ_HANDLED;
 }
 
-static int __init cbe_init_pm_irq(void)
+static int __init mmio_init_pm_irq(void)
 {
 	unsigned int irq;
 	int rc, node;
@@ -408,7 +416,7 @@ static int __init cbe_init_pm_irq(void)
 			return -EINVAL;
 		}
 
-		rc = request_irq(irq, cbe_pm_irq,
+		rc = request_irq(irq, mmio_pm_irq,
 				 IRQF_DISABLED, "cbe-pmu-0", NULL);
 		if (rc) {
 			printk("ERROR: Request for irq on node %d failed\n",
@@ -419,4 +427,11 @@ static int __init cbe_init_pm_irq(void)
 
 	return 0;
 }
-machine_arch_initcall(cell, cbe_init_pm_irq);
+
+static int __init mmio_pmu_init(void)
+{
+	cell_pmu_ops_init(&cell_pmu_ops_mmio);
+	return mmio_init_pm_irq();
+}
+
+machine_arch_initcall(cell, mmio_pmu_init);

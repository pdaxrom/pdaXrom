From linux-rt-users-owner@vger.kernel.org Fri Aug 24 21:03:45 2007
Return-Path: <linux-rt-users-owner@vger.kernel.org>
X-Spam-Checker-Version: SpamAssassin 3.1.7-deb (2006-10-05) on debian
X-Spam-Level: 
X-Spam-Status: No, score=0.0 required=5.0 tests=AWL autolearn=unavailable 
	version=3.1.7-deb
Received: from vger.kernel.org (vger.kernel.org [209.132.176.167]) by
	mail.tglx.de (Postfix) with ESMTP id 71A6F65C292; Fri, 24 Aug 2007 21:03:45
	+0200 (CEST)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand id
	S1759776AbXHXTDo (ORCPT <rfc822;jan.altenberg@linutronix.de> + 1 other);
	Fri, 24 Aug 2007 15:03:44 -0400
Received: (majordomo@vger.kernel.org) by vger.kernel.org id
	S1757790AbXHXTDo (ORCPT <rfc822;linux-rt-users-outgoing>); Fri, 24 Aug 2007
	15:03:44 -0400
Received: from ms-smtp-02.nyroc.rr.com ([24.24.2.56]:35989 "EHLO
	ms-smtp-02.nyroc.rr.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org with
	ESMTP id S1756831AbXHXTDn (ORCPT <rfc822;linux-rt-users@vger.kernel.org>);
	Fri, 24 Aug 2007 15:03:43 -0400
Received: from gandalf.stny.rr.com (cpe-24-94-51-176.stny.res.rr.com
	[24.94.51.176]) by ms-smtp-02.nyroc.rr.com (8.13.6/8.13.6) with ESMTP id
	l7OJ2TVR004473; Fri, 24 Aug 2007 15:02:30 -0400 (EDT)
Received: from localhost ([127.0.0.1] ident=rostedt) by gandalf.stny.rr.com
	with esmtp (Exim 4.67) (envelope-from <rostedt@goodmis.org>) id
	1IOeQP-0001Cj-Lf; Fri, 24 Aug 2007 15:02:29 -0400
Subject: [PATCH RT 3/3 - take two ] fix get_monotonic_cycles for latency
	tracer
From:	Steven Rostedt <rostedt@goodmis.org>
To:	Ingo Molnar <mingo@elte.hu>
Cc:	LKML <linux-kernel@vger.kernel.org>, RT <linux-rt-users@vger.kernel.org>, Thomas Gleixner <tglx@linutronix.de>, john stultz <johnstul@us.ibm.com>
In-Reply-To: <1187978236.2941.19.camel@localhost.localdomain>
References: <1187978236.2941.19.camel@localhost.localdomain>
Content-Type: text/plain
Date:	Fri, 24 Aug 2007 15:02:29 -0400
Message-Id: <1187982149.4574.1.camel@localhost.localdomain>
Mime-Version: 1.0
X-Mailer: Evolution 2.10.2 
X-Virus-Scanned: Symantec AntiVirus Scan Engine
Sender:	linux-rt-users-owner@vger.kernel.org
Precedence: bulk
X-Mailing-List:	linux-rt-users@vger.kernel.org
X-Filter-To: .Kernel.rt-users
X-Evolution-Source: imap://tglx%40linutronix.de@localhost:8993/
Content-Transfer-Encoding: 8bit

[Added comment about not being able to take the xtime lock in  
 get_monotonic_cycles - suggested by John Stultz]

The latency tracer on SMP was given crazy results. It was found that the
get_monotonic_cycles that it uses was not returning a monotonic counter.
The cause of this was that clock->cycles_raw and clock->cycles_last can
be updated on another CPU and make the cycles_now variable out-of-date.
So the delta that was calculated from cycles_now - cycles_last was
incorrect.

This patch adds a loop to make sure that the cycles_raw and cycles_last
are consistent through out the calculation (otherwise it performs the
loop again).

With this patch the latency_tracer can produce normal results again.

Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

---
 kernel/time/timekeeping.c |   32 ++++++++++++++++++++++++++------
 1 file changed, 26 insertions(+), 6 deletions(-)

Index: linux-2.6.23.1-rt5/kernel/time/timekeeping.c
===================================================================
--- linux-2.6.23.1-rt5.orig/kernel/time/timekeeping.c
+++ linux-2.6.23.1-rt5/kernel/time/timekeeping.c
@@ -117,15 +117,35 @@ static inline void __get_realtime_clock_
 
 cycle_t notrace get_monotonic_cycles(void)
 {
-	cycle_t cycle_now, cycle_delta;
+	cycle_t cycle_now, cycle_delta, cycle_raw, cycle_last;
 
-	/* read clocksource: */
-	cycle_now = clocksource_read(clock);
+	do {
+		/*
+		 * cycle_raw and cycle_last can change on
+		 * another CPU and we need the delta calculation
+		 * of cycle_now and cycle_last happen atomic, as well
+		 * as the adding to cycle_raw. We don't need to grab
+		 * any locks, we just keep trying until get all the
+		 * calculations together in one state.
+		 *
+		 * In fact, we __cant__ grab any locks. This
+		 * function is called from the latency_tracer which can
+		 * be called anywhere. To grab any locks (including
+		 * seq_locks) we risk putting ourselves into a deadlock.
+		 */
+		cycle_raw = clock->cycle_raw;
+		cycle_last = clock->cycle_last;
+
+		/* read clocksource: */
+		cycle_now = clocksource_read(clock);
+
+		/* calculate the delta since the last update_wall_time: */
+		cycle_delta = (cycle_now - cycle_last) & clock->mask;
 
-	/* calculate the delta since the last update_wall_time: */
-	cycle_delta = (cycle_now - clock->cycle_last) & clock->mask;
+	} while (cycle_raw != clock->cycle_raw ||
+		 cycle_last != clock->cycle_last);
 
-	return clock->cycle_raw + cycle_delta;
+	return cycle_raw + cycle_delta;
 }
 
 unsigned long notrace cycles_to_usecs(cycle_t cycles)

[PATCH 1/3] mitigate-resched-interrupt-floods

Mitigate rescheduling interrupt floods.

Background: preempt-rt sends a resched interrupt to all
other cpus whenever some realtime task gets preempted.
This is to give that task a chance to continue running
on some other cpu.  Unfortunately this can cause 'resched
interrupt floods' when there are large numbers of realtime
tasks on the system that are continually being preempted.

This patch reduces such interrupts by noting that it is
not necessary to send rescheduling interrupts to every cpu
in the system, just to those cpus in the affinity mask of
the task to be migrated.

This works well in the real world, as traditionally
realtime tasks are carefully targeted to specific cpus or
sets of cpus, meaning users often give such tasks reduced
affinity masks.

Signed-off-by: Joe Korty <joe.korty@ccur.com>

---
 arch/i386/kernel/smp.c   |    9 +++++++++
 arch/x86_64/kernel/smp.c |    9 +++++++++
 include/asm-i386/smp.h   |    2 ++
 include/asm-x86_64/smp.h |    3 +++
 include/linux/smp.h      |   10 ++++++++++
 5 files changed, 33 insertions(+)

Index: linux-2.6.23.1-rt5/arch/i386/kernel/smp.c
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/i386/kernel/smp.c
+++ linux-2.6.23.1-rt5/arch/i386/kernel/smp.c
@@ -18,6 +18,7 @@
 #include <linux/cache.h>
 #include <linux/interrupt.h>
 #include <linux/cpu.h>
+#include <linux/cpumask.h>
 #include <linux/module.h>
 
 #include <asm/mtrr.h>
@@ -486,6 +487,14 @@ void smp_send_reschedule_allbutself(void
 	send_IPI_allbutself(RESCHEDULE_VECTOR);
 }
 
+void smp_send_reschedule_allbutself_cpumask(cpumask_t mask)
+{
+	cpu_clear(smp_processor_id(), mask);
+	cpus_and(mask, mask, cpu_online_map);
+	if (!cpus_empty(mask))
+		send_IPI_mask(mask, RESCHEDULE_VECTOR);
+}
+
 /*
  * Structure and data for smp_call_function(). This is designed to minimise
  * static memory requirements. It also looks cleaner.
Index: linux-2.6.23.1-rt5/arch/x86_64/kernel/smp.c
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/x86_64/kernel/smp.c
+++ linux-2.6.23.1-rt5/arch/x86_64/kernel/smp.c
@@ -15,6 +15,7 @@
 #include <linux/delay.h>
 #include <linux/spinlock.h>
 #include <linux/smp.h>
+#include <linux/cpumask.h>
 #include <linux/kernel_stat.h>
 #include <linux/mc146818rtc.h>
 #include <linux/interrupt.h>
@@ -304,6 +305,14 @@ void smp_send_reschedule_allbutself(void
 	send_IPI_allbutself(RESCHEDULE_VECTOR);
 }
 
+void smp_send_reschedule_allbutself_cpumask(cpumask_t mask)
+{
+	cpu_clear(smp_processor_id(), mask);
+	cpus_and(mask, mask, cpu_online_map);
+	if (!cpus_empty(mask))
+		send_IPI_mask(mask, RESCHEDULE_VECTOR);
+}
+
 /*
  * Structure and data for smp_call_function(). This is designed to minimise
  * static memory requirements. It also looks cleaner.
Index: linux-2.6.23.1-rt5/include/asm-i386/smp.h
===================================================================
--- linux-2.6.23.1-rt5.orig/include/asm-i386/smp.h
+++ linux-2.6.23.1-rt5/include/asm-i386/smp.h
@@ -179,4 +179,6 @@ static __inline int logical_smp_processo
 #endif
 #endif
 
+#define HAVE_RESCHEDULE_ALLBUTSELF_CPUMASK 1
+
 #endif
Index: linux-2.6.23.1-rt5/include/asm-x86_64/smp.h
===================================================================
--- linux-2.6.23.1-rt5.orig/include/asm-x86_64/smp.h
+++ linux-2.6.23.1-rt5/include/asm-x86_64/smp.h
@@ -113,5 +113,8 @@ static __inline int logical_smp_processo
 #else
 #define cpu_physical_id(cpu)		boot_cpu_id
 #endif /* !CONFIG_SMP */
+
+#define HAVE_RESCHEDULE_ALLBUTSELF_CPUMASK 1
+
 #endif
 
Index: linux-2.6.23.1-rt5/include/linux/smp.h
===================================================================
--- linux-2.6.23.1-rt5.orig/include/linux/smp.h
+++ linux-2.6.23.1-rt5/include/linux/smp.h
@@ -7,6 +7,7 @@
  */
 
 #include <linux/errno.h>
+#include <linux/cpumask.h>
 
 extern void cpu_idle(void);
 
@@ -43,6 +44,14 @@ extern void smp_send_reschedule_allbutse
  */
 extern void smp_send_reschedule_allbutself(void);
 
+#ifdef HAVE_RESCHEDULE_ALLBUTSELF_CPUMASK
+extern void smp_send_reschedule_allbutself_cpumask(cpumask_t);
+#else
+static inline void smp_send_reschedule_allbutself_cpumask(cpumask_t mask) {
+	smp_send_reschedule_allbutself();
+}
+#endif
+
 
 /*
  * Prepare machine for booting other CPUs.
@@ -108,6 +117,7 @@ static inline int up_smp_call_function(v
 	})
 static inline void smp_send_reschedule(int cpu) { }
 static inline void smp_send_reschedule_allbutself(void) { }
+static inline void smp_send_reschedule_allbutself_cpumask(cpumask_t mask) { }
 #define num_booting_cpus()			1
 #define smp_prepare_boot_cpu()			do {} while (0)
 #define smp_call_function_single(cpuid, func, info, retry, wait) \

 arch/x86_64/kernel/early_printk.c |    2 +-
 arch/x86_64/kernel/head64.c       |    6 +++++-
 arch/x86_64/kernel/i8259.c        |    2 +-
 arch/x86_64/kernel/io_apic.c      |   13 +++++++------
 arch/x86_64/kernel/nmi.c          |    2 ++
 arch/x86_64/kernel/process.c      |   23 +++++++++++++----------
 arch/x86_64/kernel/signal.c       |    7 +++++++
 arch/x86_64/kernel/smp.c          |   14 ++++++++++++--
 arch/x86_64/kernel/traps.c        |    5 ++---
 include/asm-x86_64/acpi.h         |    4 ++--
 include/asm-x86_64/hw_irq.h       |    2 +-
 include/asm-x86_64/io_apic.h      |    2 +-
 include/asm-x86_64/spinlock.h     |    6 +++---
 include/asm-x86_64/tlbflush.h     |    8 +++++++-
 include/asm-x86_64/vgtod.h        |    2 +-
 15 files changed, 65 insertions(+), 33 deletions(-)

Index: linux-2.6.23.1-rt5/arch/x86_64/kernel/early_printk.c
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/x86_64/kernel/early_printk.c
+++ linux-2.6.23.1-rt5/arch/x86_64/kernel/early_printk.c
@@ -203,7 +203,7 @@ static int early_console_initialized = 0
 
 void early_printk(const char *fmt, ...)
 {
-	char buf[512];
+	static char buf[512];
 	int n;
 	va_list ap;
 
Index: linux-2.6.23.1-rt5/arch/x86_64/kernel/head64.c
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/x86_64/kernel/head64.c
+++ linux-2.6.23.1-rt5/arch/x86_64/kernel/head64.c
@@ -26,7 +26,11 @@ static void __init zap_identity_mappings
 {
 	pgd_t *pgd = pgd_offset_k(0UL);
 	pgd_clear(pgd);
-	__flush_tlb();
+	/*
+	 * preempt_disable/enable does not work this early in the
+	 * bootup yet:
+	 */
+	write_cr3(read_cr3());
 }
 
 /* Don't add a printk in there. printk relies on the PDA which is not initialized 
Index: linux-2.6.23.1-rt5/arch/x86_64/kernel/i8259.c
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/x86_64/kernel/i8259.c
+++ linux-2.6.23.1-rt5/arch/x86_64/kernel/i8259.c
@@ -96,8 +96,8 @@ static void (*interrupt[NR_VECTORS - FIR
  */
 
 static int i8259A_auto_eoi;
-DEFINE_SPINLOCK(i8259A_lock);
 static void mask_and_ack_8259A(unsigned int);
+DEFINE_RAW_SPINLOCK(i8259A_lock);
 
 static struct irq_chip i8259A_chip = {
 	.name		= "XT-PIC",
Index: linux-2.6.23.1-rt5/arch/x86_64/kernel/io_apic.c
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/x86_64/kernel/io_apic.c
+++ linux-2.6.23.1-rt5/arch/x86_64/kernel/io_apic.c
@@ -90,8 +90,8 @@ int timer_over_8254 __initdata = 1;
 /* Where if anywhere is the i8259 connect in external int mode */
 static struct { int pin, apic; } ioapic_i8259 = { -1, -1 };
 
-static DEFINE_SPINLOCK(ioapic_lock);
-DEFINE_SPINLOCK(vector_lock);
+static DEFINE_RAW_SPINLOCK(ioapic_lock);
+DEFINE_RAW_SPINLOCK(vector_lock);
 
 /*
  * # of IRQ routing registers
@@ -204,6 +204,9 @@ static inline void io_apic_sync(unsigned
 		reg ACTION;						\
 		io_apic_modify(entry->apic, reg);			\
 		FINAL;							\
+		 /* Force POST flush by reading: */			\
+		reg = io_apic_read(entry->apic, 0x10 + R + pin*2);	\
+									\
 		if (!entry->next)					\
 			break;						\
 		entry = irq_2_pin + entry->next;			\
@@ -348,10 +351,8 @@ static void add_pin_to_irq(unsigned int 
 	static void name##_IO_APIC_irq (unsigned int irq)		\
 	__DO_ACTION(R, ACTION, FINAL)
 
-DO_ACTION( __mask,             0, |= 0x00010000, io_apic_sync(entry->apic) )
-						/* mask = 1 */
-DO_ACTION( __unmask,           0, &= 0xfffeffff, )
-						/* mask = 0 */
+DO_ACTION( __mask,             0, |= 0x00010000, ) /* mask = 1 */
+DO_ACTION( __unmask,           0, &= 0xfffeffff, ) /* mask = 0 */
 
 DO_ACTION( __pcix_mask,   0, &= 0xffff7fff, ) /* edge */
 DO_ACTION( __pcix_unmask, 0, = (reg & 0xfffeffff) | 0x00008000, ) /* level */
Index: linux-2.6.23.1-rt5/arch/x86_64/kernel/nmi.c
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/x86_64/kernel/nmi.c
+++ linux-2.6.23.1-rt5/arch/x86_64/kernel/nmi.c
@@ -70,7 +70,9 @@ static int endflag __initdata = 0;
  */
 static __init void nmi_cpu_busy(void *data)
 {
+#ifndef CONFIG_PREEMPT_RT
 	local_irq_enable_in_hardirq();
+#endif
 	/* Intentionally don't use cpu_relax here. This is
 	   to make sure that the performance counter really ticks,
 	   even if there is a simulator or similar that catches the
Index: linux-2.6.23.1-rt5/arch/x86_64/kernel/process.c
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/x86_64/kernel/process.c
+++ linux-2.6.23.1-rt5/arch/x86_64/kernel/process.c
@@ -117,7 +117,7 @@ static void default_idle(void)
 	 */
 	smp_mb();
 	local_irq_disable();
-	if (!need_resched()) {
+	if (!need_resched() && !need_resched_delayed()) {
 		/* Enables interrupts one instruction before HLT.
 		   x86 special cases this so there is no race. */
 		safe_halt();
@@ -203,7 +203,7 @@ void cpu_idle (void)
 	current_thread_info()->status |= TS_POLLING;
 	/* endless idle loop with no priority at all */
 	while (1) {
-		while (!need_resched()) {
+		while (!need_resched() && !need_resched_delayed()) {
 			void (*idle)(void);
 
 			if (__get_cpu_var(cpu_idle_state))
@@ -231,12 +231,14 @@ void cpu_idle (void)
 			__exit_idle();
 		}
 
-		trace_preempt_exit_idle();
 		tick_nohz_restart_sched_tick();
-		preempt_enable_no_resched();
-		schedule();
+		local_irq_disable();
+		trace_preempt_exit_idle();
+		__preempt_enable_no_resched();
+		__schedule();
 		preempt_disable();
 		trace_preempt_enter_idle();
+		local_irq_enable();
 	}
 }
 
@@ -252,10 +254,10 @@ void cpu_idle (void)
  */
 void mwait_idle_with_hints(unsigned long eax, unsigned long ecx)
 {
-	if (!need_resched()) {
+	if (!need_resched() && !need_resched_delayed()) {
 		__monitor((void *)&current_thread_info()->flags, 0, 0);
 		smp_mb();
-		if (!need_resched())
+		if (!need_resched() && !need_resched_delayed())
 			__mwait(eax, ecx);
 	}
 }
@@ -263,10 +265,10 @@ void mwait_idle_with_hints(unsigned long
 /* Default MONITOR/MWAIT with no hints, used for default C1 state */
 static void mwait_idle(void)
 {
-	if (!need_resched()) {
+	if (!need_resched() && !need_resched_delayed()) {
 		__monitor((void *)&current_thread_info()->flags, 0, 0);
 		smp_mb();
-		if (!need_resched()) {
+		if (!need_resched() && !need_resched_delayed()) {
 			trace_hardirqs_on();
 			__sti_mwait(0, 0);
 		} else
@@ -385,7 +387,7 @@ void exit_thread(void)
 	struct thread_struct *t = &me->thread;
 
 	if (me->thread.io_bitmap_ptr) { 
-		struct tss_struct *tss = &per_cpu(init_tss, get_cpu());
+		struct tss_struct *tss;
 
 		kfree(t->io_bitmap_ptr);
 		t->io_bitmap_ptr = NULL;
@@ -393,6 +395,7 @@ void exit_thread(void)
 		/*
 		 * Careful, clear this in the TSS too:
 		 */
+		tss = &per_cpu(init_tss, get_cpu());
 		memset(tss->io_bitmap, 0xff, t->io_bitmap_max);
 		t->io_bitmap_max = 0;
 		put_cpu();
Index: linux-2.6.23.1-rt5/arch/x86_64/kernel/signal.c
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/x86_64/kernel/signal.c
+++ linux-2.6.23.1-rt5/arch/x86_64/kernel/signal.c
@@ -396,6 +396,13 @@ static void do_signal(struct pt_regs *re
 	int signr;
 	sigset_t *oldset;
 
+#ifdef CONFIG_PREEMPT_RT
+	/*
+	 * Fully-preemptible kernel does not need interrupts disabled:
+	 */
+	local_irq_enable();
+	preempt_check_resched();
+#endif
 	/*
 	 * We want the common case to go fast, which
 	 * is why we may in certain cases get here from
Index: linux-2.6.23.1-rt5/arch/x86_64/kernel/smp.c
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/x86_64/kernel/smp.c
+++ linux-2.6.23.1-rt5/arch/x86_64/kernel/smp.c
@@ -56,7 +56,7 @@ union smp_flush_state {
 		struct mm_struct *flush_mm;
 		unsigned long flush_va;
 #define FLUSH_ALL	-1ULL
-		spinlock_t tlbstate_lock;
+		raw_spinlock_t tlbstate_lock;
 	};
 	char pad[SMP_CACHE_BYTES];
 } ____cacheline_aligned;
@@ -295,10 +295,20 @@ void smp_send_reschedule(int cpu)
 }
 
 /*
+ * this function sends a 'reschedule' IPI to all other CPUs.
+ * This is used when RT tasks are starving and other CPUs
+ * might be able to run them:
+ */
+void smp_send_reschedule_allbutself(void)
+{
+	send_IPI_allbutself(RESCHEDULE_VECTOR);
+}
+
+/*
  * Structure and data for smp_call_function(). This is designed to minimise
  * static memory requirements. It also looks cleaner.
  */
-static DEFINE_SPINLOCK(call_lock);
+static DEFINE_RAW_SPINLOCK(call_lock);
 
 struct call_data_struct {
 	void (*func) (void *info);
Index: linux-2.6.23.1-rt5/arch/x86_64/kernel/traps.c
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/x86_64/kernel/traps.c
+++ linux-2.6.23.1-rt5/arch/x86_64/kernel/traps.c
@@ -219,7 +219,7 @@ void dump_trace(struct task_struct *tsk,
 		unsigned long *stack,
 		struct stacktrace_ops *ops, void *data)
 {
-	const unsigned cpu = get_cpu();
+	const unsigned cpu = raw_smp_processor_id();
 	unsigned long *irqstack_end = (unsigned long*)cpu_pda(cpu)->irqstackptr;
 	unsigned used = 0;
 	struct thread_info *tinfo;
@@ -310,7 +310,6 @@ void dump_trace(struct task_struct *tsk,
 	tinfo = task_thread_info(tsk);
 	HANDLE_STACK (valid_stack_ptr(tinfo, stack));
 #undef HANDLE_STACK
-	put_cpu();
 }
 EXPORT_SYMBOL(dump_trace);
 
@@ -360,7 +359,7 @@ _show_stack(struct task_struct *tsk, str
 {
 	unsigned long *stack;
 	int i;
-	const int cpu = smp_processor_id();
+	const int cpu = raw_smp_processor_id();
 	unsigned long *irqstack_end = (unsigned long *) (cpu_pda(cpu)->irqstackptr);
 	unsigned long *irqstack = (unsigned long *) (cpu_pda(cpu)->irqstackptr - IRQSTACKSIZE);
 
Index: linux-2.6.23.1-rt5/include/asm-x86_64/acpi.h
===================================================================
--- linux-2.6.23.1-rt5.orig/include/asm-x86_64/acpi.h
+++ linux-2.6.23.1-rt5/include/asm-x86_64/acpi.h
@@ -51,8 +51,8 @@
 
 #define ACPI_ASM_MACROS
 #define BREAKPOINT3
-#define ACPI_DISABLE_IRQS() local_irq_disable()
-#define ACPI_ENABLE_IRQS()  local_irq_enable()
+#define ACPI_DISABLE_IRQS() local_irq_disable_nort()
+#define ACPI_ENABLE_IRQS()  local_irq_enable_nort()
 #define ACPI_FLUSH_CPU_CACHE()	wbinvd()
 
 int __acpi_acquire_global_lock(unsigned int *lock);
Index: linux-2.6.23.1-rt5/include/asm-x86_64/hw_irq.h
===================================================================
--- linux-2.6.23.1-rt5.orig/include/asm-x86_64/hw_irq.h
+++ linux-2.6.23.1-rt5/include/asm-x86_64/hw_irq.h
@@ -118,7 +118,7 @@ void i8254_timer_resume(void);
 typedef int vector_irq_t[NR_VECTORS];
 DECLARE_PER_CPU(vector_irq_t, vector_irq);
 extern void __setup_vector_irq(int cpu);
-extern spinlock_t vector_lock;
+extern raw_spinlock_t vector_lock;
 
 /*
  * Various low-level irq details needed by irq.c, process.c,
Index: linux-2.6.23.1-rt5/include/asm-x86_64/io_apic.h
===================================================================
--- linux-2.6.23.1-rt5.orig/include/asm-x86_64/io_apic.h
+++ linux-2.6.23.1-rt5/include/asm-x86_64/io_apic.h
@@ -131,6 +131,6 @@ extern int sis_apic_bug; /* dummy */ 
 
 void enable_NMI_through_LVT0 (void * dummy);
 
-extern spinlock_t i8259A_lock;
+extern raw_spinlock_t i8259A_lock;
 
 #endif
Index: linux-2.6.23.1-rt5/include/asm-x86_64/spinlock.h
===================================================================
--- linux-2.6.23.1-rt5.orig/include/asm-x86_64/spinlock.h
+++ linux-2.6.23.1-rt5/include/asm-x86_64/spinlock.h
@@ -160,8 +160,8 @@ static inline void __raw_write_unlock(__
 				: "=m" (rw->lock) : : "memory");
 }
 
-#define _raw_spin_relax(lock)	cpu_relax()
-#define _raw_read_relax(lock)	cpu_relax()
-#define _raw_write_relax(lock)	cpu_relax()
+#define __raw_spin_relax(lock)	cpu_relax()
+#define __raw_read_relax(lock)	cpu_relax()
+#define __raw_write_relax(lock)	cpu_relax()
 
 #endif /* __ASM_SPINLOCK_H */
Index: linux-2.6.23.1-rt5/include/asm-x86_64/tlbflush.h
===================================================================
--- linux-2.6.23.1-rt5.orig/include/asm-x86_64/tlbflush.h
+++ linux-2.6.23.1-rt5/include/asm-x86_64/tlbflush.h
@@ -8,14 +8,20 @@
 
 static inline void __flush_tlb(void)
 {
+	preempt_disable();
 	write_cr3(read_cr3());
+	preempt_enable();
 }
 
 static inline void __flush_tlb_all(void)
 {
-	unsigned long cr4 = read_cr4();
+	unsigned long cr4;
+
+	preempt_disable();
+	cr4 = read_cr4();
 	write_cr4(cr4 & ~X86_CR4_PGE);	/* clear PGE */
 	write_cr4(cr4);			/* write old PGE again and flush TLBs */
+	preempt_enable();
 }
 
 #define __flush_tlb_one(addr) \
Index: linux-2.6.23.1-rt5/include/asm-x86_64/vgtod.h
===================================================================
--- linux-2.6.23.1-rt5.orig/include/asm-x86_64/vgtod.h
+++ linux-2.6.23.1-rt5/include/asm-x86_64/vgtod.h
@@ -5,7 +5,7 @@
 #include <linux/clocksource.h>
 
 struct vsyscall_gtod_data {
-	seqlock_t	lock;
+	raw_seqlock_t	lock;
 
 	/* open coded 'struct timespec' */
 	time_t		wall_time_sec;

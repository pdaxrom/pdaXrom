 arch/x86_64/ia32/ia32entry.S  |   11 ++++++++-
 arch/x86_64/kernel/entry.S    |   45 +++++++++++++++++++++++++++++++++++++
 arch/x86_64/kernel/head64.c   |    3 +-
 arch/x86_64/kernel/irq.c      |    6 +++++
 arch/x86_64/kernel/setup64.c  |    4 +--
 arch/x86_64/kernel/smpboot.c  |    2 -
 arch/x86_64/kernel/traps.c    |    1 
 arch/x86_64/kernel/vsyscall.c |    2 -
 include/asm-x86_64/calling.h  |   50 ++++++++++++++++++++++++++++++++++++++++++
 include/asm-x86_64/unistd.h   |    2 +
 10 files changed, 120 insertions(+), 6 deletions(-)

Index: linux-2.6.23.1-rt5/arch/x86_64/ia32/ia32entry.S
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/x86_64/ia32/ia32entry.S
+++ linux-2.6.23.1-rt5/arch/x86_64/ia32/ia32entry.S
@@ -132,7 +132,9 @@ sysenter_do_call:	
 	cmpl	$(IA32_NR_syscalls-1),%eax
 	ja	ia32_badsys
 	IA32_ARG_FIXUP 1
+	TRACE_SYS_IA32_CALL
 	call	*ia32_sys_call_table(,%rax,8)
+	TRACE_SYS_RET
 	movq	%rax,RAX-ARGOFFSET(%rsp)
 	GET_THREAD_INFO(%r10)
 	cli
@@ -241,7 +243,9 @@ cstar_do_call:	
 	cmpl $IA32_NR_syscalls-1,%eax
 	ja  ia32_badsys
 	IA32_ARG_FIXUP 1
+	TRACE_SYS_IA32_CALL
 	call *ia32_sys_call_table(,%rax,8)
+	TRACE_SYS_RET
 	movq %rax,RAX-ARGOFFSET(%rsp)
 	GET_THREAD_INFO(%r10)
 	cli
@@ -335,8 +339,10 @@ ia32_do_syscall:	
 	cmpl $(IA32_NR_syscalls-1),%eax
 	ja  ia32_badsys
 	IA32_ARG_FIXUP
+	TRACE_SYS_IA32_CALL
 	call *ia32_sys_call_table(,%rax,8) # xxx: rip relative
 ia32_sysret:
+	TRACE_SYS_RET
 	movq %rax,RAX-ARGOFFSET(%rsp)
 	jmp int_ret_from_sys_call 
 
@@ -407,7 +413,7 @@ END(ia32_ptregs_common)
 
 	.section .rodata,"a"
 	.align 8
-ia32_sys_call_table:
+ENTRY(ia32_sys_call_table)
 	.quad sys_restart_syscall
 	.quad sys_exit
 	.quad stub32_fork
@@ -733,4 +739,7 @@ ia32_sys_call_table:
 	.quad compat_sys_timerfd
 	.quad sys_eventfd
 	.quad sys32_fallocate
+#ifdef CONFIG_EVENT_TRACE
+ .globl ia32_syscall_end
+#endif
 ia32_syscall_end:
Index: linux-2.6.23.1-rt5/arch/x86_64/kernel/entry.S
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/x86_64/kernel/entry.S
+++ linux-2.6.23.1-rt5/arch/x86_64/kernel/entry.S
@@ -53,6 +53,47 @@
 
 	.code64
 
+#ifdef CONFIG_EVENT_TRACE
+
+ENTRY(mcount)
+	cmpl $0, mcount_enabled
+	jz out
+
+	push %rbp
+	mov %rsp,%rbp
+
+	push %r11
+	push %r10
+	push %r9
+	push %r8
+	push %rdi
+	push %rsi
+	push %rdx
+	push %rcx
+	push %rax
+
+	mov 0x0(%rbp),%rax
+	mov 0x8(%rbp),%rdi
+	mov 0x8(%rax),%rsi
+
+	call   __trace
+
+	pop %rax
+	pop %rcx
+	pop %rdx
+	pop %rsi
+	pop %rdi
+	pop %r8
+	pop %r9
+	pop %r10
+	pop %r11
+
+	pop %rbp
+out:
+	ret
+
+#endif
+
 #ifndef CONFIG_PREEMPT
 #define retint_kernel retint_restore_args
 #endif	
@@ -234,7 +275,9 @@ ENTRY(system_call)
 	cmpq $__NR_syscall_max,%rax
 	ja badsys
 	movq %r10,%rcx
+	TRACE_SYS_CALL
 	call *sys_call_table(,%rax,8)  # XXX:	 rip relative
+	TRACE_SYS_RET
 	movq %rax,RAX-ARGOFFSET(%rsp)
 /*
  * Syscall return path ending with SYSRET (fast path)
@@ -316,7 +359,9 @@ tracesys:			 
 	cmova %rcx,%rax
 	ja  1f
 	movq %r10,%rcx	/* fixup for C */
+	TRACE_SYS_CALL
 	call *sys_call_table(,%rax,8)
+ 	TRACE_SYS_RET
 1:	movq %rax,RAX-ARGOFFSET(%rsp)
 	/* Use IRET because user could have changed frame */
 		
Index: linux-2.6.23.1-rt5/arch/x86_64/kernel/head64.c
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/x86_64/kernel/head64.c
+++ linux-2.6.23.1-rt5/arch/x86_64/kernel/head64.c
@@ -10,6 +10,7 @@
 #include <linux/kernel.h>
 #include <linux/string.h>
 #include <linux/percpu.h>
+#include <linux/sched.h>
 
 #include <asm/processor.h>
 #include <asm/proto.h>
@@ -58,7 +59,7 @@ static void __init copy_bootdata(char *r
 	memcpy(boot_command_line, command_line, COMMAND_LINE_SIZE);
 }
 
-void __init x86_64_start_kernel(char * real_mode_data)
+void __init notrace x86_64_start_kernel(char * real_mode_data)
 {
 	int i;
 
Index: linux-2.6.23.1-rt5/arch/x86_64/kernel/irq.c
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/x86_64/kernel/irq.c
+++ linux-2.6.23.1-rt5/arch/x86_64/kernel/irq.c
@@ -117,6 +117,12 @@ asmlinkage unsigned int do_IRQ(struct pt
 	irq_enter();
 	irq = __get_cpu_var(vector_irq)[vector];
 
+#ifdef CONFIG_EVENT_TRACE
+	if (irq == trace_user_trigger_irq)
+		user_trace_start();
+#endif
+	trace_special(regs->rip, irq, 0);
+
 #ifdef CONFIG_DEBUG_STACKOVERFLOW
 	stack_overflow_check(regs);
 #endif
Index: linux-2.6.23.1-rt5/arch/x86_64/kernel/setup64.c
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/x86_64/kernel/setup64.c
+++ linux-2.6.23.1-rt5/arch/x86_64/kernel/setup64.c
@@ -114,7 +114,7 @@ void __init setup_per_cpu_areas(void)
 	}
 } 
 
-void pda_init(int cpu)
+void notrace pda_init(int cpu)
 { 
 	struct x8664_pda *pda = cpu_pda(cpu);
 
@@ -191,7 +191,7 @@ unsigned long kernel_eflags;
  * 'CPU state barrier', nothing should get across.
  * A lot of state is already set up in PDA init.
  */
-void __cpuinit cpu_init (void)
+void __cpuinit notrace cpu_init (void)
 {
 	int cpu = stack_smp_processor_id();
 	struct tss_struct *t = &per_cpu(init_tss, cpu);
Index: linux-2.6.23.1-rt5/arch/x86_64/kernel/smpboot.c
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/x86_64/kernel/smpboot.c
+++ linux-2.6.23.1-rt5/arch/x86_64/kernel/smpboot.c
@@ -316,7 +316,7 @@ static inline void set_cpu_sibling_map(i
 /*
  * Setup code on secondary processor (after comming out of the trampoline)
  */
-void __cpuinit start_secondary(void)
+void __cpuinit notrace start_secondary(void)
 {
 	/*
 	 * Dont put anything before smp_callin(), SMP
Index: linux-2.6.23.1-rt5/arch/x86_64/kernel/traps.c
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/x86_64/kernel/traps.c
+++ linux-2.6.23.1-rt5/arch/x86_64/kernel/traps.c
@@ -351,6 +351,7 @@ show_trace(struct task_struct *tsk, stru
 	printk("\nCall Trace:\n");
 	dump_trace(tsk, regs, stack, &print_trace_ops, NULL);
 	printk("\n");
+	print_traces(tsk);
 }
 
 static void
Index: linux-2.6.23.1-rt5/arch/x86_64/kernel/vsyscall.c
===================================================================
--- linux-2.6.23.1-rt5.orig/arch/x86_64/kernel/vsyscall.c
+++ linux-2.6.23.1-rt5/arch/x86_64/kernel/vsyscall.c
@@ -44,7 +44,7 @@
 #include <asm/topology.h>
 #include <asm/vgtod.h>
 
-#define __vsyscall(nr) __attribute__ ((unused,__section__(".vsyscall_" #nr)))
+#define __vsyscall(nr) __attribute__ ((unused,__section__(".vsyscall_" #nr))) notrace
 #define __syscall_clobber "r11","rcx","memory"
 #define __pa_vsymbol(x)			\
 	({unsigned long v;  		\
Index: linux-2.6.23.1-rt5/include/asm-x86_64/calling.h
===================================================================
--- linux-2.6.23.1-rt5.orig/include/asm-x86_64/calling.h
+++ linux-2.6.23.1-rt5/include/asm-x86_64/calling.h
@@ -160,3 +160,53 @@
 	.macro icebp
 	.byte 0xf1
 	.endm
+
+/*
+ * latency-tracing helpers:
+ */
+
+	.macro TRACE_SYS_CALL
+
+#ifdef CONFIG_EVENT_TRACE
+	SAVE_ARGS
+
+	mov     %rdx, %rcx
+	mov     %rsi, %rdx
+	mov     %rdi, %rsi
+	mov     %rax, %rdi
+
+	call sys_call
+
+	RESTORE_ARGS
+#endif
+	.endm
+
+
+	.macro TRACE_SYS_IA32_CALL
+
+#ifdef CONFIG_EVENT_TRACE
+	SAVE_ARGS
+
+	mov     %rdx, %rcx
+	mov     %rsi, %rdx
+	mov     %rdi, %rsi
+	mov     %rax, %rdi
+
+	call sys_ia32_call
+
+	RESTORE_ARGS
+#endif
+	.endm
+
+	.macro TRACE_SYS_RET
+
+#ifdef CONFIG_EVENT_TRACE
+	SAVE_ARGS
+
+	mov     %rax, %rdi
+
+	call sys_ret
+
+	RESTORE_ARGS
+#endif
+	.endm
Index: linux-2.6.23.1-rt5/include/asm-x86_64/unistd.h
===================================================================
--- linux-2.6.23.1-rt5.orig/include/asm-x86_64/unistd.h
+++ linux-2.6.23.1-rt5/include/asm-x86_64/unistd.h
@@ -11,6 +11,8 @@
  * Note: holes are not allowed.
  */
 
+#define NR_syscalls (__NR_syscall_max+1)
+
 /* at least 8 syscall per cacheline */
 #define __NR_read                                0
 __SYSCALL(__NR_read, sys_read)

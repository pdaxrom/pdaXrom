---
 kernel/sched.c |   38 --------------------------------------
 1 file changed, 38 deletions(-)

Index: linux-2.6.23.1-rt5/kernel/sched.c
===================================================================
--- linux-2.6.23.1-rt5.orig/kernel/sched.c
+++ linux-2.6.23.1-rt5/kernel/sched.c
@@ -3392,42 +3392,6 @@ void scheduler_tick(void)
 #endif
 }
 
-#if defined(CONFIG_EVENT_TRACE) && defined(CONFIG_DEBUG_RT_MUTEXES)
-
-static void trace_array(struct prio_array *array)
-{
-	int i;
-	struct task_struct *p;
-	struct list_head *head, *tmp;
-
-	for (i = 0; i < MAX_RT_PRIO; i++) {
-		head = array->queue + i;
-		if (list_empty(head)) {
-			WARN_ON(test_bit(i, array->bitmap));
-			continue;
-		}
-		WARN_ON(!test_bit(i, array->bitmap));
-		list_for_each(tmp, head) {
-			p = list_entry(tmp, struct task_struct, run_list);
-			trace_special_pid(p->pid, p->prio, PRIO(p));
-		}
-	}
-}
-
-static inline void trace_all_runnable_tasks(struct rq *rq)
-{
-	if (trace_enabled)
-		trace_array(&rq->active);
-}
-
-#else
-
-static inline void trace_all_runnable_tasks(struct rq *rq)
-{
-}
-
-#endif
-
 /*
  * Print scheduling while atomic bug:
  */
@@ -3536,8 +3500,6 @@ need_resched_nonpreemptible:
 	prev->sched_class->put_prev_task(rq, prev);
 	next = pick_next_task(rq, prev);
 
-	trace_all_runnable_tasks(rq);
-
 	sched_info_switch(prev, next);
 
 	if (likely(prev != next)) {
